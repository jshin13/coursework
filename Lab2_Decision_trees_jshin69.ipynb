{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2_Decision_trees_jshin69.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jshin13/code_bucket/blob/temp/Lab2_Decision_trees_jshin69.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoJKQZR2N_dl"
      },
      "source": [
        "# Lab 2: Decision trees - The CART algorithm\n",
        "\n",
        "In this lab, you will be programming your own decision tree CART algorithm with Gini criterion. \n",
        "\n",
        "In the following lines, complete the functions replacing the comments # YOUR CODE GOES HERE or the variables equal to 'None'  with your code.\n",
        "\n",
        "To evaluate the algorithm we will be working with the [Early stage diabetes risk prediction dataset](https://archive.ics.uci.edu/ml/datasets/Early+stage+diabetes+risk+prediction+dataset.) containing predictor variables about patients with diabetes and controls. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eoCMLobShUO"
      },
      "source": [
        "**0. Moving the lab to your folder**\n",
        "\n",
        "Copy this notebook to your personal directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfNdDiRiOGsi"
      },
      "source": [
        "# Library import. Feel free to add more libraries that you may use in your code\n",
        "\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "import numpy as np"
      ],
      "execution_count": 1167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udZpB3DuxZ7M"
      },
      "source": [
        "**1. Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rZ6eVhaOHr9"
      },
      "source": [
        "sData='http://archive.ics.uci.edu/ml/machine-learning-databases/00529/diabetes_data_upload.csv'\n",
        "urllib.request.urlretrieve(sData,'./datafile.csv') # The data is stored in your drive folder under the name 'datafile.csv'\n",
        "df=pd.read_csv('./datafile.csv')"
      ],
      "execution_count": 1168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdUigUd_xi77"
      },
      "source": [
        "If you print the head of the dataframe, you can observe the different predictor variables (Age, Gender, Polyuria, etc) and the labels of the first five observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VksvkUM6OLOp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "2db1995d-6e65-409b-8b3f-d864268bda65"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 1169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Polyuria</th>\n",
              "      <th>Polydipsia</th>\n",
              "      <th>sudden weight loss</th>\n",
              "      <th>weakness</th>\n",
              "      <th>Polyphagia</th>\n",
              "      <th>Genital thrush</th>\n",
              "      <th>visual blurring</th>\n",
              "      <th>Itching</th>\n",
              "      <th>Irritability</th>\n",
              "      <th>delayed healing</th>\n",
              "      <th>partial paresis</th>\n",
              "      <th>muscle stiffness</th>\n",
              "      <th>Alopecia</th>\n",
              "      <th>Obesity</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age Gender Polyuria Polydipsia  ... muscle stiffness Alopecia Obesity     class\n",
              "0   40   Male       No        Yes  ...              Yes      Yes     Yes  Positive\n",
              "1   58   Male       No         No  ...               No      Yes      No  Positive\n",
              "2   41   Male      Yes         No  ...              Yes      Yes      No  Positive\n",
              "3   45   Male       No         No  ...               No       No      No  Positive\n",
              "4   60   Male      Yes        Yes  ...              Yes      Yes     Yes  Positive\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycDAr3usyB2Z"
      },
      "source": [
        "In the next cell, you can print a single observation by selecting its correspondent series using iloc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AkBoxoEON-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acafe87c-ce16-402e-a0bc-f02540782875"
      },
      "source": [
        "series=df.iloc[3,:-1] # The last column is removed (it's the class)\n",
        "print(series)"
      ],
      "execution_count": 1170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Age                     45\n",
            "Gender                Male\n",
            "Polyuria                No\n",
            "Polydipsia              No\n",
            "sudden weight loss     Yes\n",
            "weakness               Yes\n",
            "Polyphagia             Yes\n",
            "Genital thrush         Yes\n",
            "visual blurring         No\n",
            "Itching                Yes\n",
            "Irritability            No\n",
            "delayed healing        Yes\n",
            "partial paresis         No\n",
            "muscle stiffness        No\n",
            "Alopecia                No\n",
            "Obesity                 No\n",
            "Name: 3, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQUNzL0YyQDR"
      },
      "source": [
        "**2. Dataset descriptors**\n",
        "**Data and notation used in the algorithm:**\n",
        "X is the training subset containing N observations\n",
        "Each observation, x_n is a vector containing the predictor variables (size M) for each observation.\n",
        "y_n is the label of x_n\n",
        "J: total number of classes\n",
        "N: total number of observations (number of training vectors)\n",
        "M: number of predictor variables (feature vector length)\n",
        "\n",
        "**TASK 1:** In the next cell, calculate the N, M and J."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOz9I9P8ORC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "250c19c0-40aa-4614-a8fe-f96659e1ef53"
      },
      "source": [
        "#First steps: Determine the number of features, classes and observations \n",
        "#(replace 'None' with your code) (5 POINTS)\n",
        "y=df['class']\n",
        "N=df.shape[0]\n",
        "M=series.shape[0]\n",
        "J=len(df['class'].unique())\n",
        "\n",
        "print('Number of observations: '+str(N))\n",
        "print('Number of predictor variables: '+str(M))\n",
        "print('Number of classes: '+str(J))"
      ],
      "execution_count": 1171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of observations: 520\n",
            "Number of predictor variables: 16\n",
            "Number of classes: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urb6Q1dis3c1"
      },
      "source": [
        "Expected output:\n",
        "\n",
        "Number of observations: 520\n",
        "\n",
        "Number of predictor variables: 16\n",
        "\n",
        "Number of classes: 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA7EKVC2zPl6"
      },
      "source": [
        "**TASK 2:** Split the data into, approx, 80% training and 20% testing (you can choose the first 80% observations as training and the rest as testing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UNWqKZ9dubC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232ef478-aa0f-4101-e26e-61e4fe052427"
      },
      "source": [
        "# Split the data into, approx, 80% training and 20% testing\n",
        "#(replace 'None' with your code)  (5 POINTS)\n",
        "df = df.sample(frac=1)\n",
        "dfTrain=df[:round(N*0.8)]\n",
        "dfTest=df[round(N*0.8):]\n",
        "print(dfTrain.shape[0] + dfTest.shape[0])"
      ],
      "execution_count": 1172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U5_jLb50IQz"
      },
      "source": [
        "# 3. The CART Algorithm\n",
        "*1.\tFind each predictor’s best split:*\n",
        "\n",
        "* a.\tDetermine if the predictor is categorical or numerical\n",
        "\n",
        "\n",
        "* b.\tFor each predictor, obtain unique values. \n",
        "\n",
        "* c.\tFor each predictor: using the unique values, go through each value to examine each predictor’s possible split point\n",
        "\n",
        "\n",
        "* - i.\tThe best split point (threshold) is the one that maximizes the splitting criterion1 (impurity gain) the most.\n",
        "\n",
        "* - ii.\tIn categorical predictors, we will have to consider a possible node for each category.\n",
        "\n",
        "\n",
        "*2.\tFind the predictor that provides the best split:*\n",
        "\n",
        "* a.\tSelect the predictor that maximizes the splitting criterion (the one that produces the highest impurity gain.\n",
        "\n",
        "\n",
        "*3.\tSplit the data X into two new nodes using the split point calculated in point 1 for the predictor selected in point 2.*\n",
        "\n",
        "\n",
        "*4.\tRepeat point 1 for each branch if stopping rules are not satisfied:*\n",
        "\n",
        "* a.\tStopping rules: \n",
        "* * i.\tMaximum tree depth (maximum number of nodes in a row)\n",
        "* * ii.\tAll the remaining training observations in a resulting branch belong to a single class (maximum purity)\n",
        "* * iii.\tAll observations in a node have the same predictor’s values: it is not possible to split more. \n",
        "* * iv.\tThe node size is less than the minimum node size (number of observations in a node)\n",
        "\n",
        "In the following cells, create the functions required for each point.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX5LGvXt6oCX"
      },
      "source": [
        "**TASK 3:** 1.a.  Determine if the predictor is categorical or numerical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMW-ldVNOVf2"
      },
      "source": [
        "# 1.a Is the class numerical? (5 POINTS)\n",
        "\n",
        "def is_numerical(df):\n",
        "    \"\"\"Test if values in a series are numeric and returns a vector with boolean results\"\"\"\n",
        "    #YOUR CODE GOES HERE\n",
        "    return dfTrain.iloc[0,:].astype(str).str.isnumeric().tolist()[:-1]"
      ],
      "execution_count": 1173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQT1Yn2_ObHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee739d13-9022-4ca5-e103-f5025e61b43a"
      },
      "source": [
        "# Example\n",
        "print(is_numerical(dfTrain))"
      ],
      "execution_count": 1174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eCA7SpV69RV"
      },
      "source": [
        "Expected output: \n",
        "\n",
        "\n",
        "[True,\n",
        " False,\n",
        " False,\n",
        " False,\n",
        " False,\n",
        " False,\n",
        " False,\n",
        " False,\n",
        " False,\n",
        " False,\n",
        " False,\n",
        " False,\n",
        " False,\n",
        " False,\n",
        " False,\n",
        " False]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLWuABnBZANG"
      },
      "source": [
        "**TASK 4:** 1.b. b.\tFor each predictor, obtain unique values (categories)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlLFRlZEOd9Y"
      },
      "source": [
        "#1.b Function to obtain categories per predictor (5 POINTS)\n",
        "def unique_values(df,column):\n",
        "  \"\"\"\n",
        "  This function returns a list with all the possible categories present in a predictor variable\n",
        "  Inputs: dataframe (df) and string containing the name of the predictor variable (column)\n",
        "  \"\"\"\n",
        "    #YOUR CODE GOES HERE\n",
        "  return df[column].unique().tolist()\n"
      ],
      "execution_count": 1175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "509AMNtyP5GL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62990622-7bc3-4547-ff7e-1e136dec89c8"
      },
      "source": [
        "#Example\n",
        "categories=unique_values(df,'Gender')\n",
        "print(categories)\n",
        "print(categories[0])"
      ],
      "execution_count": 1176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Male', 'Female']\n",
            "Male\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWpoPJzOZsna"
      },
      "source": [
        "Expected output:\n",
        "\n",
        "['Male' 'Female']\n",
        "\n",
        "Male"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGV2wgW8Z2rj"
      },
      "source": [
        "**TASK 5:** 1.c.\tFor each predictor: using the unique values, go through each value to examine each predictor’s possible split point\n",
        "\n",
        "1. c. i. Search for the best split point (threshold) is the one that maximizes the splitting criterion1 (impurity gain) the most."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udkwjKO6QDbr"
      },
      "source": [
        "#1.c.i Generate the gini function that calculates impurity  (15 POINTS)\n",
        "def impurity_gini(df):\n",
        "  \"\"\"\n",
        "  Calculates and returns the Gini impurity of the input dataframe (df)\n",
        "  \"\"\"\n",
        "  #YOUR CODE GOES HERE\n",
        "  temp = []\n",
        "  for i in unique_values(df,'class'):\n",
        "      temp.append((df['class'] == i).sum() / df.shape[0])  \n",
        "  return 1 - sum(np.array(temp)**2)\n",
        "\n",
        "def impurity_gain(df, dfl, dfr):\n",
        "  \"\"\"\n",
        "  Calculates and returns the Impurity Gain considering that df is used to\n",
        "  calculate the initial impurity (or node t), and dfl and dfr to calculate the\n",
        "  weights and impurities of node L and R, respectively\n",
        "  \"\"\"\n",
        "  #YOUR CODE GOES HERE\n",
        "  return impurity_gini(df) - dfl.shape[0]/df.shape[0] * impurity_gini(dfl) - dfr.shape[0]/df.shape[0] * impurity_gini(dfr) "
      ],
      "execution_count": 1177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gZgb4XOVvT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda5b380-42df-44d3-b944-f0d70f0cddb4"
      },
      "source": [
        "impurity_gini(df)"
      ],
      "execution_count": 1178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47337278106508873"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlO2hSuubf4B"
      },
      "source": [
        "Expected output: 0.47337278106508873"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr7zqMj0Vwvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ecb6db-e20e-4941-bf27-1955389170e7"
      },
      "source": [
        "impurity_gain(df,df,df)"
      ],
      "execution_count": 1179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.47337278106508873"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81f2mXvublt4"
      },
      "source": [
        "Expected output: -0.47337278106508873"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkX0wnf0gKvj"
      },
      "source": [
        "**TASK 6:** Search for the split point (or threshold) that provides the highest impurity gain in numerical predictor variables (for instance, 'Age' is a numerical variable)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_HzZaZEhlwm"
      },
      "source": [
        "#1.c.i Numerical split analysis (10 POINTS)\n",
        "def numerical_max_search(df, column):\n",
        "  \"\"\" \n",
        "  Returns the max impurity gain (ig_max) of the variable defined by 'column' in the df subset.\n",
        "  It also returns the value of the split point (category_max) that yields the \n",
        "  highest impurity gain for that variable.\n",
        "  \"\"\"\n",
        "  #YOUR CODE GOES HERE\n",
        "  ig_max = 0\n",
        "  category_max = 0\n",
        "\n",
        "  for i in unique_values(df,column):\n",
        "      dfl = df[df[column] <= i]\n",
        "      dfr = df[df[column] > i]\n",
        "      temp = impurity_gain(df,dfl,dfr)\n",
        "\n",
        "      if ig_max < temp:\n",
        "        ig_max = temp\n",
        "        category_max = i\n",
        "\n",
        "  return ig_max, category_max"
      ],
      "execution_count": 1180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0ZBaTlMiS3N",
        "outputId": "667499e6-989f-45d2-f14b-ebd8480ac773"
      },
      "source": [
        "numerical_max_search(df, 'Age')"
      ],
      "execution_count": 1181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.015152664201645794, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNbPyuF3cd-1"
      },
      "source": [
        "Expected Output:\n",
        "\n",
        "(0.015152664201645794, 34)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFPdcNYzfPxe"
      },
      "source": [
        "**TASK 7:** 1.c.\tFor each predictor: using the unique values, go through each value to examine each predictor’s possible split point\n",
        "\n",
        "1. c. ii.\tIn categorical predictors, we will have to consider a possible node for each category. This means that we have to perform a search of best split for each category. In the dataset that we are using, each of the categorical variables have only two possible categories (Yes or No - Male or Female). However, a code that consider more than 2 categories would be desirable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMgFaWs3WwOl"
      },
      "source": [
        "# 1.c.ii Categorical split analysis (10 POINTS)\n",
        "def categorical_max_search(df, column):\n",
        "    \"\"\" \n",
        "    Returns the max impurity gain (ig_max) of all categories in the variable defined by column\n",
        "    it also returns the name of the category that yields the highest impurity gain (category_max).\n",
        "    \"\"\"\n",
        "    #YOUR CODE GOES HERE\n",
        "    ig_max = 0\n",
        "    category_max = None\n",
        "\n",
        "    for i in unique_values(df, column):\n",
        "        dfl = df[df[column] == i]\n",
        "        dfr = df[df[column] != i]\n",
        "        temp = impurity_gain(df, dfl, dfr)\n",
        "\n",
        "        if ig_max < temp:\n",
        "            ig_max = temp\n",
        "            category_max = i\n",
        "\n",
        "    return ig_max, category_max"
      ],
      "execution_count": 1182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgv0GgHVfAAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c28b4a-cd71-4e0c-d973-7bd5c85634c3"
      },
      "source": [
        "categorical_max_search(df, 'Polydipsia')"
      ],
      "execution_count": 1183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.19922151623026904, 'No')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1183
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiTE0Xk_gyZF"
      },
      "source": [
        "Expected output: (0.19922151623026907, 'No')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVvBZLAUhubb"
      },
      "source": [
        "**TASK 8:** 2.\tUsing the previous functions, find the predictor that provides the best split: \n",
        "a.\tSelect the predictor that maximizes the splitting criterion (the one that produces the highest impurity gain).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kDBxHx1hQc6"
      },
      "source": [
        "# 2.a Find predictor that provides best split (10 POINTS)\n",
        "def find_max_predictor(df):\n",
        "  \"\"\"\n",
        "  This function finds the predictor variable (Max_predictor), category or threshold\n",
        "  (Max_category) and their associated impurity gain (Max_ig) in the input dataset (df)\n",
        "  using the previous functions \n",
        "  \"\"\"\n",
        "  #YOUR CODE GOES HERE\n",
        "  Max_ig = 0\n",
        "  Max_predictor = None\n",
        "  Max_category = None\n",
        "\n",
        "  for idx, i in enumerate(is_numerical(df)): #iterate over is_numerical bool\n",
        "      if i:\n",
        "        temp_ig, temp_cat = numerical_max_search(df, df.columns[idx]) # if numerical, do numerical search\n",
        "      else:\n",
        "        temp_ig, temp_cat = categorical_max_search(df, df.columns[idx]) # if not numerical, do categorical search \n",
        "\n",
        "      if Max_ig < temp_ig: # if better impurity gain\n",
        "          Max_ig = temp_ig # update max impurity gain\n",
        "          Max_predictor = df.columns[idx] # update max predictor\n",
        "          Max_category = temp_cat # update max category\n",
        "\n",
        "  return Max_ig, Max_predictor, Max_category"
      ],
      "execution_count": 1184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq7XSA5JomDU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e21cb5-3395-4b06-8d08-d917df7e3fba"
      },
      "source": [
        "# Example\n",
        "Max_ig, Max_predictor, Max_category=find_max_predictor(df)\n",
        "print('Maximum Impurity Gain: ' +str(Max_ig) +' obtained with the predictor '+ Max_predictor +' and category ' +str(Max_category))"
      ],
      "execution_count": 1185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum Impurity Gain: 0.20991841189440502 obtained with the predictor Polyuria and category Yes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij7o4s3cpOFi"
      },
      "source": [
        "Expected output: \n",
        "\n",
        "Maximum Impurity Gain: 0.20991841189440502 obtained with the predictor Polyuria and category No"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwHAx0GuoeP7"
      },
      "source": [
        "**TASK 9:** 3.\tSplit any input data X (a dataframe) into two new nodes using the \n",
        "split point and predictor selected obtained with find_max_predictor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p8ZPmXgeqyu"
      },
      "source": [
        "# 3. Split data (15 POINTS)\n",
        "def split_data(df):\n",
        "    \"\"\"\n",
        "    Splits the input subset (df) into two smaller subsets (dfL and dfR) that define\n",
        "    the split that provides the highest Impurity Gain. It also returns the predictor\n",
        "    (Max_predictor) and category (Max_category) that favor that split. The code might \n",
        "    be different for numerical and categorical predictor variables.\n",
        "    \"\"\"\n",
        "\n",
        "    #YOUR CODE GOES HERE\n",
        "    _, Max_predictor, Max_category = find_max_predictor(df)\n",
        "\n",
        "    dfL = df[df[Max_predictor] == Max_category]\n",
        "    dfR = df[df[Max_predictor] != Max_category]\n",
        "  \n",
        "    return dfL,dfR, Max_predictor, Max_category "
      ],
      "execution_count": 1186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFde069petWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44955996-06ad-419e-91ea-04b31b8161f2"
      },
      "source": [
        "# This defines the first node of the tree for the df dataset\n",
        "dfL,dfR,predictor,treshold=split_data(df)\n",
        "# This calculates the Impurity Gain when going from the initial dataset (df) to \n",
        "# the left and right subsets\n",
        "impurity_gain(df,dfL,dfR)"
      ],
      "execution_count": 1187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20991841189440502"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-YfUwRXpzm1"
      },
      "source": [
        "Expected output:\n",
        "0.20991841189440502"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR2-HNADqLX0"
      },
      "source": [
        "**Additional code:**\n",
        "The following function and classes serve to store information of the nodes and leaves. You do not need to code anything here. :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep9MOdnZmzmd"
      },
      "source": [
        "def classify_leaf(df):\n",
        "  \"\"\" \n",
        "  Counts the number of observations per class (class probability) in the input df \n",
        "  This function serves to create the classification info stored in the leaf.\n",
        "  \"\"\"\n",
        "\n",
        "  classes=df.iloc[:,-1] # Labels in df\n",
        "  classes_uni=classes.unique() # this variable contains the classes that exist in df\n",
        "  result={Tclass:(sum(classes==Tclass)/len(df)) for Tclass in classes_uni} #proportion of observations per class\n",
        "  return result\n",
        "\n",
        "class tree_leaf:\n",
        "    \"\"\"\n",
        "    This class will contain the results of the leaf (ex: Positive: 0.8, Negative:0.2)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.predictions = classify_leaf(df)\n",
        "\n",
        "class tree_node:\n",
        "    \"\"\"\n",
        "    This class will contain the predictor and treshold of the node and a the two \n",
        "    nested nodes (left and right)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 predictor,\n",
        "                 threshold,\n",
        "                 left_branch,\n",
        "                 right_branch):\n",
        "        self.predictor = predictor\n",
        "        self.threshold = threshold\n",
        "        self.left_branch = left_branch\n",
        "        self.right_branch = right_branch"
      ],
      "execution_count": 1188,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp94TI9HqXIL"
      },
      "source": [
        "**TASK 10:** Stopping rules. These rules will serve to decide when to stop looking for a node and create a leaf. Conventional algorithms might have more stopping rules, but we will restrict our rules to only four conditions. You will have to code the functions that check these rules.\n",
        "\n",
        "4.a.\tStopping rules:\n",
        "\n",
        "i.\tMaximum tree depth (maximum number of nodes in a row) (this will be checked in the main function)\n",
        "\n",
        "ii.\tAll the remaining training observations in a resulting branch belong to a single class (maximum purity)\n",
        "\n",
        "iii.\tAll observations in a node have the same predictor’s values: it is not possible to split more. \n",
        "\n",
        "iv.\tThe node size is less than the minimum node size (number of observations in a node)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im4FYiWyJPpe"
      },
      "source": [
        "# check stopping rules (10 POINTS)\n",
        "\n",
        "#4.a.ii\n",
        "def check_impurity(df):\n",
        "  #returns TRUE if impurity of the data in df is equal to 0.\n",
        " \n",
        "    #YOUR CODE GOES HERE\n",
        "    if impurity_gini(df) == 0: return True\n",
        "    return False\n",
        "\n",
        "#4.a.iii\n",
        "def check_predictor(df):\n",
        "  #Checks if all the observations have exactly the same variable vectors \n",
        "  #(same values for every single predictor variable)\n",
        "    \n",
        "    #YOUR CODE GOES HERE\n",
        "    for i in df.columns:\n",
        "        if len(unique_values(df, i)) == 1:\n",
        "            pass\n",
        "        else: return False\n",
        "    return True        \n",
        "  \n",
        "#4.a.iv\n",
        "def check_node_length(df, min_partition_length):\n",
        "  #returns TRUE if the number of observations in df is less than min_partition_length\n",
        "  \n",
        "    #YOUR CODE GOES HERE (you have finished!!)\n",
        "    if df.shape[0] < min_partition_length:\n",
        "        return True\n",
        "    return False\n"
      ],
      "execution_count": 1189,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GhcHKnCrh9Q"
      },
      "source": [
        "**End of the lab: Train the tree**\n",
        "\n",
        "If all your functions have been coded as requested, the following functions should train and evaluate a decision tree. \n",
        "\n",
        "**TASK 11:** Code the training of the right (false) branch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joJ0X6aJJClU"
      },
      "source": [
        "# train the tree  (10 POINTS)\n",
        "def train_tree_mlma(df, tree_depth=0, min_partition_length=2, max_tree_depth=200):\n",
        "\n",
        "    dfL,dfR,predictor,threshold=split_data(df)\n",
        "    tree_depth+=1 #the tree depth in this path is extended\n",
        "    print('Tree depth: ' +str(tree_depth))\n",
        "    #tree_depth==max_tree_depth checks condition 4.a.i\n",
        "    #Left branch (true)\n",
        "    if check_impurity(dfL) or check_predictor(dfL) or check_node_length(dfL,min_partition_length) or tree_depth==max_tree_depth:\n",
        "        left_node=tree_leaf(dfL)\n",
        "    else:\n",
        "        left_node=train_tree_mlma(dfL, tree_depth)\n",
        "  \n",
        "    #Right branch (false)\n",
        "\n",
        "    # YOUR CODE GOES HERE\n",
        "    if check_impurity(dfR) or check_predictor(dfR) or check_node_length(dfR,min_partition_length) or tree_depth==max_tree_depth:\n",
        "        right_node=tree_leaf(dfR)\n",
        "    else:\n",
        "        right_node=train_tree_mlma(dfR, tree_depth)\n",
        "\n",
        "    return tree_node(predictor, threshold, left_node, right_node)"
      ],
      "execution_count": 1190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5-an4DJLMut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a76f53-4a04-426a-80b9-0de1187678dc"
      },
      "source": [
        "my_tree=train_tree_mlma(dfTrain)"
      ],
      "execution_count": 1191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tree depth: 1\n",
            "Tree depth: 2\n",
            "Tree depth: 3\n",
            "Tree depth: 4\n",
            "Tree depth: 5\n",
            "Tree depth: 6\n",
            "Tree depth: 7\n",
            "Tree depth: 8\n",
            "Tree depth: 4\n",
            "Tree depth: 3\n",
            "Tree depth: 4\n",
            "Tree depth: 5\n",
            "Tree depth: 6\n",
            "Tree depth: 5\n",
            "Tree depth: 6\n",
            "Tree depth: 7\n",
            "Tree depth: 8\n",
            "Tree depth: 4\n",
            "Tree depth: 5\n",
            "Tree depth: 6\n",
            "Tree depth: 5\n",
            "Tree depth: 6\n",
            "Tree depth: 2\n",
            "Tree depth: 3\n",
            "Tree depth: 3\n",
            "Tree depth: 4\n",
            "Tree depth: 5\n",
            "Tree depth: 6\n",
            "Tree depth: 7\n",
            "Tree depth: 8\n",
            "Tree depth: 9\n",
            "Tree depth: 10\n",
            "Tree depth: 11\n",
            "Tree depth: 12\n",
            "Tree depth: 13\n",
            "Tree depth: 14\n",
            "Tree depth: 15\n",
            "Tree depth: 16\n",
            "Tree depth: 17\n",
            "Tree depth: 18\n",
            "Tree depth: 19\n",
            "Tree depth: 20\n",
            "Tree depth: 21\n",
            "Tree depth: 22\n",
            "Tree depth: 23\n",
            "Tree depth: 24\n",
            "Tree depth: 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUbMrlD5N0CA"
      },
      "source": [
        "def print_tree_mlma(my_tree, jump=''):\n",
        "  jump=jump+'-'\n",
        "  if isinstance(my_tree, tree_leaf):\n",
        "    print(jump+'Result: ')\n",
        "    print(my_tree.predictions)\n",
        "  else:\n",
        "    if is_numeric_dtype(my_tree.threshold):\n",
        "      print(jump + '> If ' + str(my_tree.predictor) + ' <= ' + str(my_tree.threshold))\n",
        "      print_tree_mlma(my_tree.left_branch,jump)\n",
        "      print(jump+'> Else: ')\n",
        "      print_tree_mlma(my_tree.right_branch,jump)\n",
        "    \n",
        "    else:\n",
        "      print(jump + '> If ' + str(my_tree.predictor) + ' is ' + str(my_tree.threshold))\n",
        "      print_tree_mlma(my_tree.left_branch,jump)\n",
        "      print(jump+'> Else: ')\n",
        "      print_tree_mlma(my_tree.right_branch,jump)"
      ],
      "execution_count": 1192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LXpiaHXbnIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7c614d-9c18-4daf-c9e4-4c80355fdc3d"
      },
      "source": [
        "print_tree_mlma(my_tree)"
      ],
      "execution_count": 1193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-> If Polyuria is No\n",
            "--> If Gender is Female\n",
            "---> If Alopecia is No\n",
            "----> If Age is 34\n",
            "-----Result: \n",
            "{'Negative': 1.0}\n",
            "----> Else: \n",
            "-----> If Age is 36\n",
            "------Result: \n",
            "{'Negative': 1.0}\n",
            "-----> Else: \n",
            "------> If Age is 33\n",
            "-------Result: \n",
            "{'Negative': 1.0}\n",
            "------> Else: \n",
            "-------> If Age is 28\n",
            "--------> If Polyphagia is No\n",
            "---------Result: \n",
            "{'Positive': 1.0}\n",
            "--------> Else: \n",
            "---------Result: \n",
            "{'Negative': 1.0}\n",
            "-------> Else: \n",
            "--------Result: \n",
            "{'Positive': 1.0}\n",
            "---> Else: \n",
            "----> If delayed healing is No\n",
            "-----Result: \n",
            "{'Positive': 1.0}\n",
            "----> Else: \n",
            "-----Result: \n",
            "{'Negative': 1.0}\n",
            "--> Else: \n",
            "---> If Polydipsia is No\n",
            "----> If Irritability is Yes\n",
            "-----> If Genital thrush is Yes\n",
            "------Result: \n",
            "{'Positive': 1.0}\n",
            "-----> Else: \n",
            "------> If Age is 42\n",
            "-------Result: \n",
            "{'Positive': 1.0}\n",
            "------> Else: \n",
            "-------Result: \n",
            "{'Negative': 1.0}\n",
            "----> Else: \n",
            "-----> If Alopecia is Yes\n",
            "------> If Age is 37\n",
            "-------Result: \n",
            "{'Positive': 1.0}\n",
            "------> Else: \n",
            "-------> If partial paresis is No\n",
            "--------Result: \n",
            "{'Negative': 1.0}\n",
            "-------> Else: \n",
            "--------> If Itching is Yes\n",
            "---------Result: \n",
            "{'Negative': 1.0}\n",
            "--------> Else: \n",
            "---------Result: \n",
            "{'Positive': 1.0}\n",
            "-----> Else: \n",
            "------Result: \n",
            "{'Negative': 1.0}\n",
            "---> Else: \n",
            "----> If muscle stiffness is Yes\n",
            "-----> If delayed healing is No\n",
            "------Result: \n",
            "{'Negative': 1.0}\n",
            "-----> Else: \n",
            "------> If Age is 56\n",
            "-------Result: \n",
            "{'Negative': 1.0}\n",
            "------> Else: \n",
            "-------Result: \n",
            "{'Positive': 1.0}\n",
            "----> Else: \n",
            "-----> If partial paresis is No\n",
            "------Result: \n",
            "{'Positive': 1.0}\n",
            "-----> Else: \n",
            "------> If Age is 49\n",
            "-------Result: \n",
            "{'Negative': 1.0}\n",
            "------> Else: \n",
            "-------Result: \n",
            "{'Positive': 1.0}\n",
            "-> Else: \n",
            "--> If Age is 70\n",
            "---> If sudden weight loss is Yes\n",
            "----Result: \n",
            "{'Positive': 1.0}\n",
            "---> Else: \n",
            "----Result: \n",
            "{'Negative': 1.0}\n",
            "--> Else: \n",
            "---> If Age is 69\n",
            "----Result: \n",
            "{'Positive': 1.0}\n",
            "---> Else: \n",
            "----> If Age is 66\n",
            "-----Result: \n",
            "{'Positive': 1.0}\n",
            "----> Else: \n",
            "-----> If Age is 63\n",
            "------Result: \n",
            "{'Positive': 1.0}\n",
            "-----> Else: \n",
            "------> If Age is 62\n",
            "-------Result: \n",
            "{'Positive': 1.0}\n",
            "------> Else: \n",
            "-------> If Age is 61\n",
            "--------Result: \n",
            "{'Positive': 1.0}\n",
            "-------> Else: \n",
            "--------> If Age is 60\n",
            "---------Result: \n",
            "{'Positive': 1.0}\n",
            "--------> Else: \n",
            "---------> If Age is 58\n",
            "----------Result: \n",
            "{'Positive': 1.0}\n",
            "---------> Else: \n",
            "----------> If Age is 57\n",
            "-----------Result: \n",
            "{'Positive': 1.0}\n",
            "----------> Else: \n",
            "-----------> If Age is 56\n",
            "------------Result: \n",
            "{'Positive': 1.0}\n",
            "-----------> Else: \n",
            "------------> If Age is 55\n",
            "-------------Result: \n",
            "{'Positive': 1.0}\n",
            "------------> Else: \n",
            "-------------> If Age is 54\n",
            "--------------Result: \n",
            "{'Positive': 1.0}\n",
            "-------------> Else: \n",
            "--------------> If Age is 53\n",
            "---------------Result: \n",
            "{'Positive': 1.0}\n",
            "--------------> Else: \n",
            "---------------> If Age is 52\n",
            "----------------Result: \n",
            "{'Positive': 1.0}\n",
            "---------------> Else: \n",
            "----------------> If Age is 51\n",
            "-----------------Result: \n",
            "{'Positive': 1.0}\n",
            "----------------> Else: \n",
            "-----------------> If Age is 50\n",
            "------------------Result: \n",
            "{'Positive': 1.0}\n",
            "-----------------> Else: \n",
            "------------------> If Age is 49\n",
            "-------------------Result: \n",
            "{'Positive': 1.0}\n",
            "------------------> Else: \n",
            "-------------------> If Age is 48\n",
            "--------------------Result: \n",
            "{'Positive': 1.0}\n",
            "-------------------> Else: \n",
            "--------------------> If Alopecia is No\n",
            "---------------------Result: \n",
            "{'Positive': 1.0}\n",
            "--------------------> Else: \n",
            "---------------------> If Age is 41\n",
            "----------------------Result: \n",
            "{'Positive': 1.0}\n",
            "---------------------> Else: \n",
            "----------------------> If Age is 45\n",
            "-----------------------Result: \n",
            "{'Positive': 1.0}\n",
            "----------------------> Else: \n",
            "-----------------------> If Age is 40\n",
            "------------------------Result: \n",
            "{'Positive': 1.0}\n",
            "-----------------------> Else: \n",
            "------------------------> If Age is 39\n",
            "-------------------------Result: \n",
            "{'Positive': 1.0}\n",
            "------------------------> Else: \n",
            "-------------------------> If Itching is Yes\n",
            "--------------------------Result: \n",
            "{'Negative': 1.0}\n",
            "-------------------------> Else: \n",
            "--------------------------Result: \n",
            "{'Positive': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkUOlnLp80TG",
        "outputId": "b9ce9e80-c33c-4b7c-9a8d-300fb7a69282"
      },
      "source": [
        "my_series=dfTest.iloc[56,:]\r\n",
        "predictionprediction=classify_tree_mlma(my_tree, my_series )\r\n",
        "print('True class: ' + my_series[-1] + ' - ' + my_series.keys()[-1])\r\n",
        "print('Predicted class: ')\r\n",
        "print(prediction)"
      ],
      "execution_count": 1203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True class: Negative - class\n",
            "Predicted class: \n",
            "{'Positive': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J9LNrJsbaYe"
      },
      "source": [
        "def classify_tree_mlma(my_tree, my_series):\n",
        "  \"\"\"\n",
        "  Classifies the input series and returns the predictions\n",
        "  \"\"\"\n",
        "  if isinstance(my_tree, tree_leaf):\n",
        "    return my_tree.predictions\n",
        "  else:\n",
        "    if is_numeric_dtype(my_tree.threshold): # Numeric\n",
        "      if my_series[my_tree.predictor] <= my_tree.threshold:\n",
        "        return classify_tree_mlma(my_tree.left_branch,my_series)\n",
        "      else:\n",
        "        return classify_tree_mlma(my_tree.right_branch,my_series)\n",
        "    else: #Categorical\n",
        "      if my_series[my_tree.predictor] == my_tree.threshold:\n",
        "        return classify_tree_mlma(my_tree.left_branch,my_series)\n",
        "      else:\n",
        "        return classify_tree_mlma(my_tree.right_branch,my_series)"
      ],
      "execution_count": 1200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FNH2YaTbqKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c514d2f9-5dfd-4205-8a37-7b8874a8d0fb"
      },
      "source": [
        "my_series=dfTest.iloc[33,:]\n",
        "prediction=classify_tree_mlma(my_tree, my_series)\n",
        "print('True class: ' + my_series[-1] + ' - ' + my_series.keys()[-1])\n",
        "print('Predicted class: ')\n",
        "print(prediction)"
      ],
      "execution_count": 1196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True class: Positive - class\n",
            "Predicted class: \n",
            "{'Positive': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPc3VV-nsPty"
      },
      "source": [
        "**BONUS:** \n",
        "Code a function that calculates the accuracy of the trained tree when classifying the whole dfTest subset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTrecWMjkvx6"
      },
      "source": [
        "# YOUR CODE GOES HERE (+20 POINTS)\r\n",
        "pred = []\r\n",
        "\r\n",
        "N = dfTest.shape[0]\r\n",
        "\r\n",
        "for i in range(N):\r\n",
        "    my_series=dfTest.iloc[i,:]\r\n",
        "    pred = pred + [i for i in classify_tree_mlma(my_tree, my_series).keys()]\r\n",
        "\r\n",
        "acc = sum(np.array(pred) == np.array(dfTest['class'].tolist())) / N"
      ],
      "execution_count": 1197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGBUkffhDWxD",
        "outputId": "d7faec79-08c0-4989-c861-c34ae5235d82"
      },
      "source": [
        "print(f'Accuracy is {round(acc * 100, 2)} %')"
      ],
      "execution_count": 1198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 98.08 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BL2qWs8NiL4"
      },
      "source": [
        "**You are ready to submit in Blackboard!**\n",
        "\n",
        "Please suffix your colab file with _<jhID> \n",
        "o\teg: Lab2_Decision_trees_myjhID12\n",
        "\n"
      ]
    }
  ]
}